{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/alisonmitchell/Biomedical-Knowledge-Graph/blob/main/02_Exploratory_Data_Analysis/Text_Embeddings.ipynb\"\n",
        "   target=\"_parent\">\n",
        "   <img src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "      alt=\"Open in Colab\">\n",
        "</a>\n",
        "\n",
        "# Representation Learning - Text Embeddings"
      ],
      "metadata": {
        "id": "2Ksl1UhaYWTy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "\n",
        "Text embeddings, like word embeddings, are dense vectors that capture semantic meaning but, instead of just individual words, they encode sentences and documents to facilitate comparison between larger bodies of text. They are the most common kind of embeddings stored in vector databases.\n",
        "\n",
        "The best text embedding models are built using transformers, which leverage the self-attention mechanism introduced in Vaswani et al's [\"Attention is All You Need\"](https://arxiv.org/abs/1706.03762) paper (2017), marking a turning point and becoming the state-of-the-art (SOTA) architecture in NLP. The self-attention mechanism captures every word's interactions with every other word in a sequence meaning that word (token) embeddings are no longer static but dynamic and contextually-aware. Positional embeddings convey word order by adding information about a word's relative or absolute position within the sequence into its word embedding, allowing the transformer to understand the context and relationships between words."
      ],
      "metadata": {
        "id": "LBAmecgCER8j"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GotL7AHRzHCv"
      },
      "source": [
        "## 2. Install/import libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install embedding-explorer embetter[text]"
      ],
      "metadata": {
        "id": "frKLMauE3Thr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kdxd5a3RzHCx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from embetter.text import SentenceEncoder\n",
        "from embedding_explorer import show_network_explorer\n",
        "from embedding_explorer import show_clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M92JsoEC_BOa"
      },
      "source": [
        "## 3. Sentence Transformers\n",
        "\n",
        "Transformers allow use of the same 'core' model and fine-tuning it for different use cases by swapping the last few layers without retraining the core model. This led to the rise of generalist pretrained language models (PLMs) leveraging the idea of transfer learning, and supervised fine-tuning on domain/task-specific data. One of the first and most popular PLMs was [Google's BERT](https://arxiv.org/abs/1810.04805) (Bidirectional Encoder Representations from Transformers).\n",
        "\n",
        "Initially, getting useful sentence embeddings from BERT was problematic and relied on one of two approaches: averaging values across all token embeddings output by BERT, or using the output of the first `[CLS]` token embedding that is trained to encode the entire input text and is used in classification tasks. However, accuracy proved to be worse than using mean GloVe embeddings.\n",
        "\n",
        "The breakthrough came in 2019 with the introduction of [Sentence-BERT (SBERT)](https://arxiv.org/abs/1908.10084) and the [`sentence-transformers`](https://www.sbert.net/) library. SBERT was the first transformer built to create a single vector embedding for sentences or paragraphs, and outperformed the previous SOTA models for semantic textual similarity tasks. Sentence transformers became the industry standard for embedding text with many more models having been built since the original SBERT.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iPj0j4C_BOa"
      },
      "source": [
        "## 4. Exploring Corpora with Dynamic Embedding Models\n",
        "\n",
        "We will use the [embedding-explorer](https://centre-for-humanities-computing.github.io/embedding-explorer/) \"network explorer\" app to explore semantic networks in our corpus with a pretrained language model (PLM) from the sentence-transformers library.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Networks of N-grams with Sentence Transformers\n",
        "\n",
        "Here we will look at n-grams in our corpus, specifically four-grams, and use an embedding model to learn context-aware representations of the four-grams."
      ],
      "metadata": {
        "id": "iGt90YNo8uCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "with open('2024-03-02_pmc_arxiv_full_text_merged_plus_cleaned_article_titles_test.pickle', 'rb') as f:\n",
        "    pmc_arxiv_full_text_merged_plus_cleaned_article_titles_test = pickle.load(f)"
      ],
      "metadata": {
        "id": "KIt8AnPf0qxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pmc_arxiv_full_text_merged_plus_cleaned_article_titles_test.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4YBlFrc0wGI",
        "outputId": "c0a50b86-8e86-467d-94f6-0222ee5f8060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 20 entries, 0 to 19\n",
            "Data columns (total 13 columns):\n",
            " #   Column         Non-Null Count  Dtype \n",
            "---  ------         --------------  ----- \n",
            " 0   article_id     20 non-null     object\n",
            " 1   published      20 non-null     object\n",
            " 2   revised        20 non-null     object\n",
            " 3   title          20 non-null     object\n",
            " 4   title_cleaned  20 non-null     object\n",
            " 5   journal        20 non-null     object\n",
            " 6   authors        20 non-null     object\n",
            " 7   doi            20 non-null     object\n",
            " 8   pdf_url        20 non-null     object\n",
            " 9   text           20 non-null     object\n",
            " 10  text_cleaned   20 non-null     object\n",
            " 11  word_count     20 non-null     int64 \n",
            " 12  sent_count     20 non-null     int64 \n",
            "dtypes: int64(2), object(11)\n",
            "memory usage: 2.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training data\n",
        "corpus = pmc_arxiv_full_text_merged_plus_cleaned_article_titles_test.text_cleaned"
      ],
      "metadata": {
        "id": "sF8cmXPU7xO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use `CountVectorizer` to extract the 4000 most frequent four-grams."
      ],
      "metadata": {
        "id": "k3awgbj0f84C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a CountVectorizer for four-grams\n",
        "feature_extractor = CountVectorizer(ngram_range=(4, 4), max_features=4000)\n",
        "X = feature_extractor.fit_transform(corpus)\n",
        "\n",
        "# Get the vectoriser's vocabulary (four-grams)\n",
        "four_grams = feature_extractor.get_feature_names_out()"
      ],
      "metadata": {
        "id": "Evs_l63jFRfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "four_grams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5NaWQxxGIw3",
        "outputId": "7af7a346-38b5-45ad-f556-a56aa1fa7899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['00 97 98 nm', '12 dasabuvir nsp 12', '12 nsp 12 dasabuvir', ...,\n",
              "       'years billion investment de', 'yellow green m36 floral',\n",
              "       'youden statistic determine optimal'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(four_grams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW5Uv6r9eaas",
        "outputId": "640b089e-2635-4d66-8050-65d9b2507ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will then use the [embetter](https://github.com/koaning/embetter) package which implements scikit-learn compatible embeddings, to load the [all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2) pretrained sentence transformers model, a BERT variant. It is one of the smallest pretrained models but is stable, fast and still offers good quality embeddings."
      ],
      "metadata": {
        "id": "CYr6J2A4njkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install embetter[text]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "r-prOa90PSKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pretrained embedding model\n",
        "from embetter.text import SentenceEncoder\n",
        "\n",
        "encoder = SentenceEncoder(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "3d2b8a0859804b868aa805e5e11314a5",
            "5d03a448b9314b698e2b35eaee5d679e",
            "9f60950938f3466ab2373e695a30cf71",
            "63af6d0ffc03427b9ba7809c2aae2e13",
            "74da46affe1d47fe8cb45397093938ce",
            "d9f39473100b4faa9aa9fe8d7cd5d6b2",
            "28d20d4eb99c405ba3008335bf59b3c3",
            "86d360e572a648f8a30cdc5b9dcabf04",
            "9d1c4194938648219a044f5f50ddf07b",
            "a8846f7a50a04c0fb348d558d831d14c",
            "871936b9b8564f23a916720ab73adc2d",
            "62201b3ab1f84ddea258cd84f50c4bd4",
            "1002eae964744a7cadb49d4e89139921",
            "dbab5ce1025043c79682d34aeab66abc",
            "0d2a421e0f874dddad7d0019519a8c55",
            "4c58a04f9f984e56ad76583b80c14472",
            "b6d4a26920db4ca3ad3eaf48c12e6c52",
            "164a964f351b4942bced9b61873d004c",
            "510615ef889e4bb199402cadcc3403c1",
            "779cc156443145fd838c82e0a5bfd6f8",
            "25af59420d924fc5a708e192e2425b52",
            "7dabb719ef9c43799fa1ca75eff836a3",
            "062fd8b59c97478fb53e76aba9849224",
            "de2edd7e40924dd584837c4785e8bbb4",
            "117df1cfcb054e9a92e52cc4df42cafa",
            "cc7196415a8842b8a1f99ba26d4b1b0b",
            "d6935b0d4c674257afbbfec34a27af04",
            "2b10913922b843adbc9ff58bc0a1a51e",
            "bbefc19d92ba4f8da0dfa1fe6a90b303",
            "995aec6c0ef346b1bb2e06990ab4f819",
            "921ab390ac3442b3ab77e5f0c12161fc",
            "460e8f87f3c4441fac82c8ea7a1ab1c8",
            "b07ca5e711ed4f3188c33f59a136cdb2",
            "42224f4cb7b3456095f2c41b73e038cc",
            "942a4b961a0d454e9d8a6d7b785a1f25",
            "fbe4a0fb58334da78a4e7cb518a83cc4",
            "5c29325d59ce49f2ac5b6a9fb61ab3f9",
            "a970f0fc7d4b4093be54d544fb2cf831",
            "ccd38d2cf7a9472eb809d22a2aab0371",
            "7a5a3147e56b422184160839836bf962",
            "32e082f48edc4e5dad597b74c3539fd1",
            "c5bce33d960b4f0489540aa768903ffa",
            "5ade81d656454cec9aa980fe2ee23bb7",
            "8939debf5b17435cbdad5bfb7cf86979",
            "deec17a3f6734090a033f78dcdb09b91",
            "0b3551fc34f449c092b30b43e5708590",
            "749657720d7e4d1fa0cde3d08ce79a6a",
            "9c5a979399eb45cb85fb9dac4e5a8f48",
            "e5200a51abcd4bb583772ff83721399f",
            "3fe386b3c3af4db9930544dfb60524c8",
            "9deacbea90d74035a78b954283708c53",
            "d0b07011aadd4883858a124fb398c4a8",
            "cde7272153d5409a898b898f1b87db0b",
            "79825cc7e146409f99baf9c05d82fb47",
            "c0e1fb38ab8c4da8995fe545d4adbcd4",
            "ab4f3879befc4cd5be3a25a8d0fa4d71",
            "4af6a4d3371e4654be942318c6f889c7",
            "7d3d8056d1734c03b33045a082accbe2",
            "485ca976044d4b8295af762a34c99b81",
            "83a10f8af0af4267bb6d9d8f3203281c",
            "26aec4419bdd4db986b27ead778b0f50",
            "e6f5809fe31940e1b9b9cfbf85a33a06",
            "370bd451fca84550bf9d26c2e51986eb",
            "dd84be0e7e01452a896dcc85a2218f51",
            "04f41d84e48b42199e288e14055bf67f",
            "5c8b5287cc8941ea84188db33d033e14",
            "8c11283ae4a848e4ba7eb3568571bdb7",
            "d26ddce1e01b460a89aeba6b5f8bace9",
            "e6f63b002fbe441198deb82135ec4017",
            "1f2ab4326a32446ba9bc81582415e2b0",
            "5d9fac9414df454296f0cc6154aaf93a",
            "e192a671792d445b82c52f28ed7ed70f",
            "140f7bc3b2f94130a19f938c848dbe3a",
            "c7e15a80320a4a558989b85844c5677f",
            "845a1ce61cc74bf8839c9634074c9f78",
            "5f4b88bcb3534dcfac14e40ec4eb7e80",
            "3013a7ef8ff04b0fb6ca2d10ad34e716",
            "70dec13bc62b454696bd1b8addfe34b0",
            "1ab8383110bc40aeb7aaf48f4083d2d9",
            "8c05b12bd13247d29876b52e20282329",
            "6b2288622c3d47d9b99a6ebea574a8e2",
            "88ee8eecd0074931a6ef50a2179e5aed",
            "484f8c86ef254750b4bc74d9cb15f856",
            "58cc9c34d4d5401b8ecc6be7e0021703",
            "143e8e48a0b940a39ba0324f64f588fb",
            "af6d37234a144e03a620eb8acd95b58a",
            "741c24348af24e73844b5d24d1d51a1f",
            "a14db6068e244d4e8f72fe91dadbf730",
            "6d65cbfcb08e4c918355e7d1ce784d73",
            "726d20af14424fb095b3994fe8ee41ea",
            "5a0d1a6d2e934f0896488bd692993b58",
            "cc20a3a4073d46baa5d47d984a316bf5",
            "da80edf215124a28b1defc348eff5614",
            "996a71c638ac496b945ba4fa8c7f4ab1",
            "3196f74c79dd4a669d44a5e1d7522c32",
            "e2bddc836ca942fcbd1d5997ad922201",
            "196f9d940803413c9941c6ca1dc03f38",
            "bcda90584fb748818e601bcfd4fbe7f8",
            "941e6ea9428e45be97a2023e72466c56",
            "23a353ab0dbf4a50bac9afd8bad2387d",
            "c051e359229a4b26afc017d62bb2ddc4",
            "0749877a50db409ba0160807c6809271",
            "e9c5b69403a942128ffb159f5e393a3b",
            "f09a89dd6d624bf0a1297c7b24bc2a4d",
            "587d18e81cf644128c6c7a07aa59e0ea",
            "3151a2648a744ff283f7c51b5ee19b4c",
            "760c7056573d4809957ee536ea07ae12",
            "afb85b8e41374efdb7ffa220d1da963d",
            "3fafc60825204fa2b02c3476fe0fd092",
            "5bbdf7325bd24a5bb6200d074cb5c934",
            "126decbae0584f1f8ea6130a55f13fe6",
            "101fb6c37c2045228e1e0bf7a76df367",
            "775c494be68f411e9e9b6824ce1cb9b9",
            "2fec8523547f4949bd90a0ad91b761dd",
            "a0fe784efcce4bc584b2720daa0112c8",
            "7bbd22c92e804527a682b13aa2daa581",
            "ee0149d89f85463288a361ec2ea5f1dc",
            "973753d8291243d88f5a2cef334992ce",
            "6e3c9b9c06bc434abc89e77697f11ea2",
            "fb92cde2c53c4b67a7e0d29677efc78a",
            "a4ffc151fac54151906ba3257bf4a54b"
          ]
        },
        "id": "wdcGV2hiQGkX",
        "outputId": "23947e40-56ac-4e6e-cd5b-a7a0ca6db4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d2b8a0859804b868aa805e5e11314a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62201b3ab1f84ddea258cd84f50c4bd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "062fd8b59c97478fb53e76aba9849224"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42224f4cb7b3456095f2c41b73e038cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "deec17a3f6734090a033f78dcdb09b91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab4f3879befc4cd5be3a25a8d0fa4d71"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c11283ae4a848e4ba7eb3568571bdb7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70dec13bc62b454696bd1b8addfe34b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d65cbfcb08e4c918355e7d1ce784d73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23a353ab0dbf4a50bac9afd8bad2387d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "126decbae0584f1f8ea6130a55f13fe6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model and the n-grams into embedding-explorer and launch network explorer app\n",
        "show_network_explorer(four_grams, vectorizer=encoder)"
      ],
      "metadata": {
        "id": "q2a92zdU9PHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can specify seeds of arbitrary length instead of just the four-grams in our corpus, including whole sentences, and it will still make sense. The screenshots below show two combinations of two sentences and the semantic networks arising from the four-grams around them."
      ],
      "metadata": {
        "id": "eIBM6nvjmJh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Cambridge scientists have identified 200 approved drugs predicted to work against COVID-19' and 'Remdesivir is effective against many RNA viruses'\n",
        "\n",
        "![network explorer four-grams example 1](images/sent_trf_four_grams.png)\n",
        "\n",
        "There is a connection between the first pair of sentences of RNA-dependent RNA polymerase (RdRp) inhibitors, and COVID-19 patients remdesivir as phrases in the middle of the two sentence clusters."
      ],
      "metadata": {
        "id": "ynfrfggvb2Zo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "'Remdesivir is effective against many RNA viruses' again , and 'The pandemic led to remarkable efforts to quickly develop new therapeutics'\n",
        "\n",
        "![network explorer four-grams example 2](images/sent_trf_four_grams_v2.png)\n",
        "\n",
        "RNA-dependent RNA polymerase (RdRp) inhibitors and COVID-19 patients remdesivir appear in the middle again but with an additional node for 'outbreak detect treat avoid' which is colour-coded for 'Remdesivir is effective against many RNA viruses' but located with 'outbreak great efforts therapeutic', a first level association of 'The pandemic led to remarkable efforts to quickly develop new therapeutics'."
      ],
      "metadata": {
        "id": "SoLiqaskphbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Investigating Corpus-Level Semantic Structure with Document Embeddings\n",
        "\n",
        "We can also investigate semantic representations at the document level. One approach to this is topic modelling which we will address separately. Here we will continue using the four-grams and sentence transformers with the same embedding model, but associate them with the indices and titles of the articles we extracted them from."
      ],
      "metadata": {
        "id": "-Nn5JErRYVbj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_list = []\n",
        "\n",
        "# Loop through each four-gram and summarise the documents that contain it\n",
        "for i, four_gram in enumerate(four_grams):\n",
        "    doc_indices = []\n",
        "    doc_titles = []\n",
        "\n",
        "    # Loop through each document\n",
        "    for index in range(len(pmc_arxiv_full_text_merged_plus_cleaned_article_titles_test)):\n",
        "        if X.toarray()[index, i] != 0:  # Check for presence of the four-gram in the doc\n",
        "            doc_indices.append(index)\n",
        "            doc_titles.append(pmc_arxiv_full_text_merged_plus_cleaned_article_titles_test['title_cleaned'].iloc[index])\n",
        "\n",
        "    # Combine document information for each four-gram\n",
        "    metadata_list.append({\n",
        "        'four_gram': four_gram,\n",
        "        'index': ', '.join(map(str, doc_indices)),\n",
        "        'title': ', '.join(doc_titles)\n",
        "    })\n",
        "\n",
        "# Convert the list to a DataFrame\n",
        "metadata_df = pd.DataFrame(metadata_list)"
      ],
      "metadata": {
        "id": "dEPXNKR6IVIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rhp5oabxI5FV",
        "outputId": "7593420f-a6f3-4aff-c45b-8d3404feed86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                               four_gram index  \\\n",
              "0                            00 97 98 nm     8   \n",
              "1                    12 dasabuvir nsp 12     8   \n",
              "2                    12 nsp 12 dasabuvir     8   \n",
              "3                    12 ribavirin nsp 12     8   \n",
              "4                       12 sars cov ns5b     8   \n",
              "...                                  ...   ...   \n",
              "3995   world health organization january  5, 7   \n",
              "3996        wos core collection database     0   \n",
              "3997         years billion investment de     7   \n",
              "3998             yellow green m36 floral     4   \n",
              "3999  youden statistic determine optimal    17   \n",
              "\n",
              "                                                  title  \n",
              "0     Structural Homology-Based Drug Repurposing App...  \n",
              "1     Structural Homology-Based Drug Repurposing App...  \n",
              "2     Structural Homology-Based Drug Repurposing App...  \n",
              "3     Structural Homology-Based Drug Repurposing App...  \n",
              "4     Structural Homology-Based Drug Repurposing App...  \n",
              "...                                                 ...  \n",
              "3995  Novel Drug Design for Treatment of COVID-19: A...  \n",
              "3996       Drug repositioning: A bibliometric analysis.  \n",
              "3997  A comprehensive review of artificial intellige...  \n",
              "3998  Drug Repurposing Using Gene Co-Expression and ...  \n",
              "3999  DeepLPI: a novel deep learning-based model for...  \n",
              "\n",
              "[4000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b814b516-dc46-4936-bca3-edf2b6de189e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>four_gram</th>\n",
              "      <th>index</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00 97 98 nm</td>\n",
              "      <td>8</td>\n",
              "      <td>Structural Homology-Based Drug Repurposing App...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12 dasabuvir nsp 12</td>\n",
              "      <td>8</td>\n",
              "      <td>Structural Homology-Based Drug Repurposing App...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12 nsp 12 dasabuvir</td>\n",
              "      <td>8</td>\n",
              "      <td>Structural Homology-Based Drug Repurposing App...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12 ribavirin nsp 12</td>\n",
              "      <td>8</td>\n",
              "      <td>Structural Homology-Based Drug Repurposing App...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12 sars cov ns5b</td>\n",
              "      <td>8</td>\n",
              "      <td>Structural Homology-Based Drug Repurposing App...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>world health organization january</td>\n",
              "      <td>5, 7</td>\n",
              "      <td>Novel Drug Design for Treatment of COVID-19: A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>wos core collection database</td>\n",
              "      <td>0</td>\n",
              "      <td>Drug repositioning: A bibliometric analysis.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>years billion investment de</td>\n",
              "      <td>7</td>\n",
              "      <td>A comprehensive review of artificial intellige...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>yellow green m36 floral</td>\n",
              "      <td>4</td>\n",
              "      <td>Drug Repurposing Using Gene Co-Expression and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>youden statistic determine optimal</td>\n",
              "      <td>17</td>\n",
              "      <td>DeepLPI: a novel deep learning-based model for...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b814b516-dc46-4936-bca3-edf2b6de189e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b814b516-dc46-4936-bca3-edf2b6de189e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b814b516-dc46-4936-bca3-edf2b6de189e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2be424bd-5728-4b4e-8ab7-ff936ce1131d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2be424bd-5728-4b4e-8ab7-ff936ce1131d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2be424bd-5728-4b4e-8ab7-ff936ce1131d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_eb579c42-d0fa-4d5e-95c3-b2b6030c0abb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('metadata_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_eb579c42-d0fa-4d5e-95c3-b2b6030c0abb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('metadata_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "metadata_df",
              "summary": "{\n  \"name\": \"metadata_df\",\n  \"rows\": 4000,\n  \"fields\": [\n    {\n      \"column\": \"four_gram\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4000,\n        \"samples\": [\n          \"main protease co crystal\",\n          \"potent drugs repurposed treatment\",\n          \"like compound covid 19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"index\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 169,\n        \"samples\": [\n          \"7, 10, 19\",\n          \"2, 12\",\n          \"15, 19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 169,\n        \"samples\": [\n          \"A comprehensive review of artificial intelligence and network based approaches to drug repurposing in Covid-19., Recent computational drug repositioning strategies against SARS-CoV-2., Artificial Neural Network-Based Study Predicts GS-441524 as a Potential Inhibitor of SARS-CoV-2 Activator Protein Furin: a Polypharmacology Approach.\",\n          \"Repurposing Molnupiravir as a new opportunity to treat COVID-19, Drug Repurposing: a Shortcut to New Biological Entities\",\n          \"In Silico Study towards Repositioning of FDA-Approved Drug Candidates for Anticoronaviral Therapy: Molecular Docking, Molecular Dynamics and Binding Free Energy Calculations., Artificial Neural Network-Based Study Predicts GS-441524 as a Potential Inhibitor of SARS-CoV-2 Activator Protein Furin: a Polypharmacology Approach.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(four_grams)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIRGbmP-JIK-",
        "outputId": "6581018d-ca11-4cec-dac9-47f614933f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('2024-09-29_four_gram_metadata_df.pickle', 'wb') as f:\n",
        "  pickle.dump(metadata_df, f)"
      ],
      "metadata": {
        "id": "-tLloC87JYoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The DataFrame has a row for each four-gram with some appearing in multiple documents as indicated in the index and title columns."
      ],
      "metadata": {
        "id": "oZrRfSfmhJu5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Projection and clustering\n",
        "\n",
        "We can also use [embedding-explorer's \"show clustering\" app](https://centre-for-humanities-computing.github.io/embedding-explorer/projection_clustering.html) for projecting whole embedding spaces into two dimensions and investigating the natural clusters that arise in the data. Various parameters can be selected such as dimensionality reduction method and number of dimensions to reduce embeddings to, clustering method and number of clusters to find, and projection method to 2D space."
      ],
      "metadata": {
        "id": "rehFQFs2Ps5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from embedding_explorer import show_clustering"
      ],
      "metadata": {
        "id": "T3ZWorLDF0AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_clustering(\n",
        "    four_grams,  # The four-grams as the input for clustering\n",
        "    vectorizer=encoder,  # The sentence transformer encoder\n",
        "    metadata=metadata_df,  # Summarised metadata DataFrame with four-gram, indices, and titles\n",
        "    hover_data=['four_gram', 'index', 'title']  # Tooltip data to display on hover\n",
        ")"
      ],
      "metadata": {
        "id": "lv7Q4-rEOWph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qodLkaOEwPt"
      },
      "source": [
        "#### 4.3.1  SVD - K-Means - SVD\n",
        "\n",
        "Screenshot of SVD for dimensionality reduction to 10 dimensions, K-means clustering for 10 clusters, and SVD for 2D projection.\n",
        "\n",
        "![SVD - K-Means - SVD](images/SVD_Kmeans_SVD.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QmG18HBEwPw"
      },
      "source": [
        "#### 4.3.2 SVD - K-Means - TSNE\n",
        "\n",
        "Screenshot of SVD for dimensionality reduction to 10 dimensions, K-means clustering for 10 clusters, and t-SNE for 2D projection.\n",
        "\n",
        "![SVD - K-Means - TSNE](images/SVD_Kmeans_TSNE_tooltip.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX8sYKNfEwPy"
      },
      "source": [
        "#### 4.3.3 UMAP - K-Means - UMAP\n",
        "\n",
        "Screenshot of UMAP for dimensionality reduction to 10 dimensions, K-means clustering for 10 clusters, and UMAP for 2D projection.\n",
        "\n",
        "![UMAP - K-Means - UMAP](images/UMAP_Kmeans_UMAP_tooltip.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4.3.4 UMAP - HDBSCAN - TSNE\n",
        "\n",
        "Screenshot of UMAP for dimensionality reduction to 10 dimensions, HDBSCAN (no maximum cluster size), and t-SNE for 2D projection.\n",
        "\n",
        "![UMAP - HDBSCAN - TSNE](images/UMAP_HDBSCAN_TSNE_tooltip.png)\n",
        "\n",
        "And another showing a data point associated with two articles:\n",
        "\n",
        "\n",
        "![UMAP - HDBSCAN - TSNE two articles](images/UMAP_HDBSCAN_TSNE_tooltip_2.png)"
      ],
      "metadata": {
        "id": "bMoqPdf5TzxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Choosing an embedding model\n",
        "\n",
        "Encoder-only models like BERT would seem the logical choice for text embeddings given their bidirectional understanding of context when transforming raw input text into contextualised dense vector representations. However, due to the  rich representations learned during training, GPT-style decoder models can also produce text embeddings despite their primary function being generation rather than encoding.\n",
        "\n",
        "OpenAI's `text-embedding-ada-002` released in December 2022, is now outperformed by `text-embedding-3-small` and `text-embedding-3-large`, the newest and most performant embedding models according to the [embeddings guide](https://platform.openai.com/docs/guides/embeddings).  \n",
        "\n",
        "We will try an example sentence with `text-embedding-3-small`."
      ],
      "metadata": {
        "id": "5t56qz0QSbkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "wKtpCH5YoDSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH6TbJoP1ffN"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5bSNStG2S6o"
      },
      "outputs": [],
      "source": [
        "with open(\"api_keys.json\") as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUZ7fFa45Lb_"
      },
      "outputs": [],
      "source": [
        "openai.api_key = data['keys'][\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=openai.api_key)\n",
        "\n",
        "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
        "   return client.embeddings.create(\n",
        "       input = [text],\n",
        "       model=model).data[0].embedding"
      ],
      "metadata": {
        "id": "qeZPo2WYpDeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = get_embedding(\"Cambridge scientists have identified 200 approved drugs predicted to work against COVID-19.\")"
      ],
      "metadata": {
        "id": "QmMSalLhpipU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('2024-09-30_openai_text_embedding_3-sm.pickle', 'wb') as f:\n",
        "  pickle.dump(embedding, f)"
      ],
      "metadata": {
        "id": "mPyDxHHeqeAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjJkdoWxq_02",
        "outputId": "b558a478-85b7-49f7-d3ff-1ee53ea4afd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.007050425745546818, -0.047010645270347595, 0.01667741872370243, 0.027381885796785355, -0.04302867874503136, -0.008783753030002117, -0.030614307150244713, 0.03654041141271591, -0.026655763387680054, -0.006622949615120888, 0.021912535652518272, -0.03269898518919945, -0.013339593075215816, 0.04178724065423012, 0.006154483184218407, -0.049189016222953796, -0.05574755370616913, 0.010440954007208347, -0.014299949631094933, 0.05223404988646507, 0.008473393507301807, 0.027592696249485016, -0.02599990926682949, 0.0044709304347634315, 0.0208467748016119, -0.02532063238322735, 0.005024306941777468, -0.001714295824058354, -0.006576103158295155, -0.003856067545711994, 0.036680951714515686, -0.019078312441706657, -0.008742761798202991, 0.0367746464908123, -0.03480708599090576, -0.029888182878494263, -0.006658084690570831, -0.003487149951979518, -0.03541609272360802, -0.002150555606931448, -0.03511158749461174, 0.002393572824075818, 0.012683738954365253, 0.03518185764551163, -0.09561408311128616, -0.0015430125640705228, -0.03759446367621422, -0.0495169423520565, -0.020085515454411507, -0.004397732205688953, 0.005712367594242096, -0.01154770702123642, -0.07247181981801987, 0.04366111010313034, -0.02131524123251438, 0.013936888426542282, -0.06563220173120499, 0.0267728790640831, -0.008028349839150906, -0.007753125857561827, 0.032043132930994034, 0.011576986871659756, 0.03911697864532471, 0.002091997070237994, -0.027826929464936256, -0.016244087368249893, 0.010710323229432106, -0.03019268810749054, 0.021244971081614494, 0.0016367059433832765, 0.015681928023695946, 0.029560256749391556, 0.046776413917541504, 0.012894549407064915, 0.0011082168202847242, -0.031293585896492004, -0.004728586878627539, 0.013070224784314632, 0.007677000015974045, 0.0014507832238450646, 0.006851327605545521, 0.021842265501618385, 0.026936842128634453, -0.05897997319698334, -0.042302556335926056, -0.02599990926682949, -0.0028415441047400236, -0.007583306636661291, -0.03464312106370926, -0.03267556056380272, -0.030778270214796066, 0.006242320407181978, -0.04928271099925041, 0.01023014448583126, -0.06286824494600296, 0.020811639726161957, 0.03342510759830475, -0.009094112552702427, 0.013761213049292564, 0.03560347855091095, 0.006019798573106527, 0.008163034915924072, -0.027592696249485016, -0.0022823119070380926, 0.035252127796411514, 0.05101603642106056, 0.03907013311982155, -0.025133244693279266, 0.046542178839445114, 0.053639452904462814, 0.04295840859413147, -0.02679630182683468, -0.03799265995621681, 0.004538272507488728, -0.005993447732180357, -0.016349492594599724, -0.044082727283239365, 0.01250806450843811, -0.004462146665900946, -0.004918901715427637, -0.03560347855091095, 0.03365934267640114, 0.02369271032512188, -0.034479159861803055, -0.0015781476395204663, 0.028529629111289978, -0.02371613308787346, -0.04270075261592865, 0.0004684668383561075, -0.02247469685971737, -0.04539443552494049, 0.029513409361243248, 0.023610727861523628, 0.03452600538730621, 0.008895013481378555, -0.00945131853222847, 0.008742761798202991, 0.010025190189480782, -0.020624252036213875, -0.023060278967022896, 0.035462938249111176, -0.051437657326459885, -0.007870242930948734, 0.02118641324341297, -0.02871701680123806, -0.0958014652132988, -0.041553009301424026, 0.02076479233801365, -0.030122417956590652, -0.007741414476186037, -0.018972907215356827, 0.015775620937347412, 0.041646700352430344, 0.021151278167963028, 0.05054756999015808, -0.013046801090240479, 0.0013351304223760962, 0.035720594227313995, -0.0005219013546593487, -0.01595129631459713, -0.04017103090882301, 0.002595599042251706, 0.013761213049292564, 0.02824855037033558, 0.03923409804701805, 0.04279444366693497, 0.012672027572989464, -0.02024947851896286, -0.04637821763753891, 0.012707162648439407, 0.02752242609858513, 0.02234586700797081, 0.022310731932520866, 0.0175792183727026, -0.030567459762096405, 0.02475847117602825, 0.035205282270908356, 0.01434679701924324, -0.04288813844323158, -0.056122325360774994, -0.03712599724531174, -0.020155785605311394, 0.0026790446136146784, -0.017145885154604912, 0.01075716968625784, -0.012765721417963505, -0.046612448990345, 0.0027654182631522417, -0.04000706598162651, -0.04199805110692978, 0.025180092081427574, -0.001285355887375772, 0.041107963770627975, 0.060479067265987396, -0.02356388233602047, -0.026889996603131294, -0.022123346105217934, 0.0055864667519927025, 0.07710964232683182, -0.05504485219717026, -0.05054756999015808, -0.0025604639668017626, -0.018328765407204628, -0.010780593380331993, -0.0037565184757113457, -0.030989080667495728, 0.005448854994028807, 0.05157819762825966, 0.013456709682941437, -0.017075616866350174, 0.04619082808494568, 0.0065058330073952675, 0.001835804432630539, 0.031246736645698547, -0.014885533601045609, -0.02696026675403118, 0.017110750079154968, -0.029044942930340767, 0.016501743346452713, 0.0479007326066494, -0.014159410260617733, -0.030754847452044487, 0.06277455389499664, 0.003835572162643075, 0.015599945560097694, -0.017860297113656998, 0.007032858207821846, 0.012800856493413448, -0.015400847420096397, -0.02623414248228073, -0.02341162972152233, -0.010353117249906063, -0.01838732324540615, -0.02843593619763851, -0.04003049060702324, -0.04277102276682854, 0.08268439769744873, -0.01031798217445612, -0.0180242620408535, -0.06492950022220612, 0.00840312335640192, -0.013913464732468128, -0.012262118980288506, 0.0029967238660901785, -0.014862109906971455, 0.018129665404558182, -0.018855789676308632, -0.06211870163679123, -0.058043040335178375, 0.022486407309770584, 0.010282847099006176, 0.009392759762704372, 0.06104122847318649, -0.05766826495528221, -0.013538691215217113, -0.0250395517796278, -0.0038619234692305326, -0.0037243112456053495, -0.02581252157688141, 0.05640340596437454, -0.05125027149915695, 0.01556481048464775, -0.03461970016360283, -0.03998364508152008, -0.03780527412891388, 0.03928094357252121, -0.007155830971896648, 0.04539443552494049, -0.05307729169726372, -0.018738673999905586, 0.04956379160284996, 0.025390902534127235, 0.04342687502503395, -0.039187248796224594, -0.048205237835645676, 0.014873822219669819, 0.022755775600671768, 0.039140403270721436, -0.051437657326459885, 0.01851615123450756, 0.0347602404654026, -0.029255753383040428, 0.018000837415456772, -0.0033290423452854156, 0.01672426611185074, 0.008239160291850567, 0.009621137753129005, -0.0015869314083829522, -0.05523223802447319, -0.0027785939164459705, 0.03579086437821388, 0.005855835508555174, -0.05598178505897522, -0.032722409814596176, -0.012004462070763111, 0.032980065792798996, -0.018469303846359253, -0.007723846938461065, -0.015482828952372074, -0.009340057149529457, 0.022029653191566467, -0.013351304456591606, 0.042817868292331696, 0.007665288634598255, 0.008233304135501385, 0.01729813776910305, -0.028904402628540993, -0.04398903623223305, -0.004667100962251425, 0.015190036967396736, 0.040897153317928314, 0.002507761586457491, 0.0015181252965703607, -0.04544128105044365, -0.004046382382512093, -0.03192601352930069, 0.03483051061630249, -0.05162504315376282, 0.022954873740673065, -0.01828191801905632, 0.010587350465357304, -0.016138682141900063, 0.04419984668493271, -0.0019587769638746977, -0.033753033727407455, 0.005044802092015743, 0.0116121219471097, -0.0059583126567304134, -0.00358669925481081, -0.018832366913557053, 0.01510805543512106, 0.06333671510219574, 0.020214343443512917, 0.015154901891946793, -0.024008924141526222, -0.03682149201631546, -0.007108984049409628, -0.03415123373270035, -0.02824855037033558, -0.04783046245574951, 0.0021622672211378813, 0.0243134293705225, 0.010247712023556232, -0.03361249342560768, 0.04117823392152786, 0.009849514812231064, -0.0260467566549778, -0.006833760067820549, 0.013936888426542282, 0.015939584001898766, -0.04569894075393677, -0.004183994140475988, -0.025156669318675995, 0.025437748059630394, -0.0010452666319906712, -0.02229902148246765, -0.004429939668625593, 0.015810756012797356, 0.00947474129498005, -0.019066600129008293, 0.03361249342560768, 0.04366111010313034, -0.023165684193372726, 0.04780704155564308, 0.008748617954552174, -0.010903565213084221, -0.03820347040891647, -0.04497281461954117, 0.026468375697731972, -0.0409674234688282, 0.03981968015432358, 0.00934591330587864, -0.019792724400758743, -0.022521542385220528, 0.0030274668242782354, 0.019898127764463425, -0.048954784870147705, 0.026093602180480957, 0.029302600771188736, 0.010967979207634926, 0.013901753351092339, 0.0037067437078803778, 0.02014407329261303, -0.002264744369313121, -0.004438723437488079, 0.013128782622516155, 0.0023086629807949066, 5.265677100396715e-05, -0.01623237505555153, -0.017462100833654404, -0.020308036357164383, -0.011202213354408741, 0.021034160628914833, 0.018141377717256546, -0.004886694718152285, 0.05860520154237747, 0.07476730644702911, 0.03211339935660362, 0.006037366110831499, 0.008613933809101582, -0.041834086179733276, -0.05504485219717026, 0.008086908608675003, 0.05429530516266823, 0.015037785284221172, -0.0041107963770627975, -0.01947650872170925, -0.0017025840934365988, 0.023833250626921654, 0.020542269572615623, 0.020202631130814552, -0.015892736613750458, 0.008303574286401272, -0.01521346066147089, 0.025203514844179153, 0.02674945630133152, 0.00505651393905282, 0.019078312441706657, -0.00871348287910223, 0.05284305661916733, 0.008116187527775764, 0.00901213102042675, -0.01882065460085869, 0.04497281461954117, 0.0012538807932287455, 0.005478133913129568, 0.03686834126710892, -0.07926458865404129, -0.01262518111616373, -0.024102618917822838, -0.04979802295565605, 0.04811154305934906, 0.029888182878494263, -0.010944556444883347, 0.006622949615120888, 0.0331440269947052, -0.024875588715076447, -0.0009310778114013374, 0.03478366136550903, 0.008748617954552174, -0.02525036223232746, 0.043590839952230453, -0.028154855594038963, -0.005273179616779089, 0.020963890478014946, -0.007097272668033838, 0.0012714482145383954, 0.007589162793010473, 0.029771067202091217, -0.003150439355522394, -0.046752989292144775, -0.026163872331380844, -0.005059441551566124, -0.01890263706445694, -0.06942678242921829, -0.04347372055053711, 0.019312545657157898, -0.04295840859413147, 0.05673133209347725, 0.051390811800956726, 0.02193595841526985, 0.02871701680123806, -0.0096972631290555, -0.0764537900686264, -0.007261235732585192, 0.02046028897166252, 0.03281610086560249, 0.024688201025128365, 0.01000762265175581, 0.008192313835024834, 0.012027885764837265, -0.03368276357650757, -0.05598178505897522, -0.0059348889626562595, 0.0375007688999176, -0.013632385060191154, 0.001600107061676681, 0.01547111663967371, 0.020553981885313988, 0.05912051349878311, -0.040850307792425156, -0.029255753383040428, -0.00039417092921212316, 0.019312545657157898, 0.05101603642106056, -0.06563220173120499, 0.030731424689292908, 0.01605669967830181, 0.02948998659849167, 0.002853255718946457, 0.033987268805503845, 0.01348013337701559, 0.014780128374695778, -0.010528791695833206, 0.020940467715263367, -0.05106288567185402, 0.009047266095876694, 0.00993149634450674, -0.0077062794007360935, 0.016033276915550232, 0.05204666405916214, 0.03394042328000069, -0.012601757422089577, 0.01856299862265587, -0.0004490693681873381, 0.02747557871043682, 0.01097969152033329, -0.012133290991187096, 0.02027290128171444, 0.0037243112456053495, -0.0186684038490057, -0.04740884155035019, -0.023060278967022896, -0.042864713817834854, -0.0019426733488216996, 0.02392694354057312, 0.0008329926058650017, 0.0019646326545625925, -7.66748416936025e-05, -0.016618860885500908, -0.002844471950083971, 0.03138727694749832, -0.030778270214796066, 0.016747688874602318, -0.027077382430434227, -0.031035928055644035, -0.02078821510076523, -0.014030581340193748, 0.00816889014095068, -0.0366106815636158, 0.0007147779106162488, 0.0026790446136146784, 0.026374682784080505, 0.047291725873947144, -0.020600829273462296, -0.03239447996020317, -0.017626063898205757, 0.010505368933081627, -0.008678347803652287, -0.01582246646285057, -0.0011587233748286963, -0.019839569926261902, -0.017626063898205757, -0.06563220173120499, -0.006271599791944027, -0.00028748493059538305, -0.005062369629740715, 0.014417066238820553, -0.019570201635360718, -0.00967384036630392, 0.01892605982720852, 0.020296325907111168, 0.019312545657157898, -0.0002732113061938435, 0.012016174383461475, -0.01275400910526514, -0.02328280173242092, -0.010885997675359249, -0.0018841150449588895, -0.021760284900665283, -0.004301111213862896, 0.010909421369433403, 0.03754761815071106, -0.006283311173319817, 0.02578909881412983, 0.030309803783893585, -0.016033276915550232, -0.013585537672042847, -0.0046846684999763966, 0.004242552910000086, -0.00891843717545271, -0.010569782927632332, -0.0024096763227134943, -0.05392053350806236, 0.017052192240953445, 0.02426658198237419, 0.02527378499507904, -0.02454766258597374, -0.03832058608531952, -0.0065058330073952675, 0.015857601538300514, 0.02102244831621647, 0.017204444855451584, 0.02941971644759178, -0.03244132921099663, 0.008414835669100285, 0.008526096120476723, -0.02078821510076523, -0.058745741844177246, -0.028178280219435692, 0.03513501212000847, -0.005355161614716053, 0.02501612901687622, 0.003894130466505885, -0.02193595841526985, -0.018094532191753387, 0.04989171773195267, 0.01373778935521841, -0.049470096826553345, 0.002500441623851657, -0.021221548318862915, -0.008976995944976807, 0.0031475115101784468, -0.02649179846048355, -0.03466654568910599, -0.017075616866350174, -0.020671099424362183, -0.036235909909009933, 0.014862109906971455, -0.008233304135501385, -0.01349184475839138, 0.003255844581872225, -0.01166482362896204, -0.01263689249753952, -0.003162151202559471, 0.004842775873839855, -0.02232244424521923, 0.01350355613976717, 0.024008924141526222, 0.00021941083832643926, -0.016021566465497017, -0.013187341392040253, -0.004251336678862572, -0.0098787946626544, -0.006213041488081217, 0.022053075954318047, 0.03464312106370926, -0.00785853061825037, 0.011969327926635742, -0.023271089419722557, 0.043590839952230453, -0.001059174188412726, -0.021900825202465057, 0.016478320583701134, -0.027616119012236595, 0.014686435461044312, -0.022263886407017708, 0.01109680812805891, 0.02550801821053028, 0.05382683873176575, 0.001125784358009696, -0.010686899535357952, -0.002889854833483696, -0.05865204706788063, 0.00662880577147007, -0.005191198084503412, -0.003536924486979842, -0.04345029965043068, -0.006986011750996113, -0.013632385060191154, -0.017731469124555588, -0.00631844624876976, 0.00429232744500041, 0.02770981378853321, -0.0008900869870558381, -0.016279222443699837, -0.013831483200192451, 2.3331844204221852e-05, 0.025367477908730507, 0.016220664605498314, 0.030497191473841667, 0.021631455048918724, 0.026163872331380844, -0.026327835395932198, -0.005753358360379934, -0.004620254039764404, 0.033026911318302155, 0.04738542065024376, -0.015881026163697243, 0.02247469685971737, -0.010727890767157078, -0.00577385351061821, 0.04082688316702843, 0.011934192851185799, 0.014405354857444763, 0.0069977231323719025, -0.013784636743366718, -0.013292746618390083, 0.0002470430626999587, 0.03391699865460396, 0.018211647868156433, 0.024945858865976334, -0.030333226546645164, 0.025484595447778702, 0.03714941814541817, -0.025625135749578476, -0.036189064383506775, 0.009058977477252483, 0.002882534870877862, 0.04192778095602989, 0.009146815165877342, -0.02778008207678795, -0.003296835348010063, -0.005065297707915306, -0.004599758889526129, -0.00946302991360426, 0.0020144074223935604, 4.105946936761029e-05, -0.014428778551518917, -0.05490431189537048, 0.0030479622073471546, 0.018117954954504967, -0.019816147163510323, -0.014826974831521511, -0.03731338307261467, 0.010522936470806599, 0.030731424689292908, 0.014627876691520214, 0.025906216353178024, 0.017368407920002937, 0.00783510785549879, -0.01350355613976717, 0.0026819726917892694, -0.0114305904135108, -0.01184635516256094, -0.005750430282205343, 0.0316917821764946, -0.013936888426542282, -0.012016174383461475, -0.02946656383574009, 0.008081052452325821, -0.014018869958817959, -0.0353223979473114, 0.0017801739741116762, 0.021151278167963028, 0.020811639726161957, 0.04867370426654816, 0.045534975826740265, 0.005817772354930639, -0.005583539139479399, 0.011237348429858685, -0.035228706896305084, 0.03171520307660103, -0.031270161271095276, 0.0006968444213271141, 0.00040844452450983226, 0.0046817404218018055, -0.021350376307964325, 0.009498164989054203, -0.02046028897166252, -0.0037418787833303213, -0.03909355774521828, -0.004438723437488079, -0.02208821102976799, -0.023552170023322105, -0.0012875518295913935, -0.0033261144999414682, -0.018703538924455643, -0.025929639115929604, -0.02998187765479088, -0.04092057794332504, 0.007589162793010473, -0.01990984007716179, 0.01153599563986063, -0.0005705779767595232, -0.040358416736125946, -0.003574987407773733, -0.02009722776710987, -0.01349184475839138, -0.006581958848983049, 0.001042338670231402, -0.0023833250161260366, 0.001151403645053506, 0.033003486692905426, -0.030871964991092682, 0.046776413917541504, 0.004517776891589165, 0.02187740057706833, -0.021455781534314156, 0.013058512471616268, -0.023364782333374023, 0.005205837544053793, -0.0243134293705225, 0.008326997980475426, 0.029279176145792007, 0.012250407598912716, 0.009047266095876694, 0.02845936082303524, -0.002734675072133541, 0.013210764154791832, -0.002040758728981018, -0.023189108818769455, -0.020062092691659927, 0.034713391214609146, -0.039398059248924255, -0.02703053690493107, 0.023083703592419624, -0.0032529165036976337, -1.880272066046018e-05, -0.007653576787561178, -0.021795419976115227, 0.04000706598162651, -0.01988641731441021, 0.006622949615120888, -0.0197575893253088, 0.013562114909291267, 0.002103708917275071, -0.08034206181764603, -0.008227448910474777, 0.005972952116280794, 0.012988243252038956, -0.04082688316702843, -0.03541609272360802, -0.0023408702109009027, 0.04045211151242256, 0.010323837399482727, -0.011805363930761814, 0.02578909881412983, -0.03869536146521568, -0.0003323186538182199, -0.014733281917870045, 0.005164846777915955, 0.011155365966260433, 0.050172798335552216, -0.040358416736125946, -0.0038502118550240993, 0.01435850840061903, 0.026679186150431633, -0.006751778069883585, -0.01952335424721241, 0.008965283632278442, -0.010001766495406628, 0.011647256091237068, 0.002310127019882202, 0.029560256749391556, 0.022205328568816185, -0.029864760115742683, -0.008004927076399326, -0.006558535620570183, -0.02499270625412464, 0.024688201025128365, -0.009796812199056149, -0.03808635473251343, -0.0173801202327013, 0.012906260788440704, -0.01012473925948143, -0.017356695607304573, -0.001436875551007688, 0.01949993148446083, 0.004309894982725382, -0.03405753895640373, -0.024360274896025658, -0.01574048586189747, -0.017227867618203163, 0.010587350465357304, -0.017860297113656998, -0.03679807111620903, -0.01130176242440939, 0.03358907252550125, -0.014381932094693184, 0.022521542385220528, -0.027850352227687836, -0.016302645206451416, 0.01783687435090542, 0.005191198084503412, -0.016349492594599724, -0.0021578753367066383, -0.03159808740019798, 0.031762052327394485, 0.011822931468486786, 0.0033788171131163836, 0.0187503844499588, 0.004620254039764404, -0.07340875267982483, 0.06043222174048424, -0.013936888426542282, 0.03239447996020317, -0.011957615613937378, 0.009808524511754513, 0.013854906894266605, 0.05134396627545357, -0.0028415441047400236, -0.025461172685027122, 0.012941395863890648, 0.006388716399669647, -0.02050713635981083, -0.0233062244951725, -0.016431473195552826, -0.04131877422332764, -0.017122462391853333, -0.030075570568442345, 0.0024433473590761423, 0.0008403123938478529, -6.464293255703524e-05, -0.0006789109320379794, 0.0030596740543842316, -0.03829716518521309, 0.006892318371683359, -0.009422038681805134, -0.002655621385201812, 0.013409863226115704, 0.01763777621090412, -0.023938655853271484, 0.008555375039577484, -0.03141070157289505, -0.02027290128171444, 0.0016249943291768432, 0.008127899840474129, -0.023470187559723854, -0.0029733004048466682, -0.019921552389860153, -0.01099140290170908, -0.01054050400853157, 0.002680508652701974, -0.0351584367454052, 0.001147011760622263, -0.008795464411377907, 0.00785853061825037, 0.03260529041290283, 0.02869359403848648, -0.0054517826065421104, -0.036423295736312866, -0.02747557871043682, 0.0006316982326097786, 0.04054580256342888, -0.0059466008096933365, 0.019312545657157898, 0.014405354857444763, -0.015119766816496849, -0.04633136838674545, 0.007267091888934374, -0.005724078975617886, 0.008953572250902653, 0.03042692132294178, 0.05040702968835831, 0.008215736597776413, 0.0009039946016855538, -0.030778270214796066, 0.0028883907943964005, 0.030614307150244713, 0.029817914590239525, 0.02291974052786827, -0.016970211640000343, 0.027147652581334114, 0.01706390455365181, 0.01074545830488205, 0.025601712986826897, 0.007840964011847973, 0.03190259262919426, -0.019195428118109703, -0.014217968098819256, 0.02245127223432064, 0.003053818130865693, -0.04984487220644951, 0.004640749655663967, -0.015482828952372074, -0.012191848829388618, 0.024360274896025658, 0.018551286309957504, 0.016501743346452713, 0.023247666656970978, -0.06254032254219055, 0.04052238166332245, 0.012859414331614971, -0.00608421303331852, -0.0034549429547041655, 0.014077427797019482, 0.001286087790504098, -0.0023511177860200405, -0.03550978749990463, 0.023528747260570526, -0.020366596058011055, 0.0018885069293901324, -0.014663011766970158, -0.018293630331754684, 0.0183053407818079, 0.04026472568511963, 0.007267091888934374, 0.005381512921303511, -0.013890041038393974, 0.011219780892133713, -0.03555663302540779, 0.04448092728853226, 0.0005039678071625531, -0.05237459018826485, 0.034479159861803055, -0.013550402596592903, 0.0011001650709658861, -0.004406515974551439, 0.008514384739100933, 0.003601338714361191, 0.0017084400169551373, -0.027147652581334114, 0.006599526386708021, 0.00999591127038002, -0.00178163789678365, -0.04227913171052933, 0.0037330950144678354, 0.03150439262390137, 0.01967560686171055, 0.032511599361896515, 0.008824744261801243, 0.02097560279071331, 0.03799265995621681, -0.006494121626019478, -0.03860166668891907, -0.012215272523462772, -0.00592317758128047, 0.02133866399526596, 0.042068321257829666, 0.043356604874134064, -0.03689176216721535, 0.02206478826701641, 0.020179208368062973, -0.030122417956590652, -0.023528747260570526, -0.047455690801143646, 0.03368276357650757, 0.04265390336513519, 0.023517034947872162, 0.037172842770814896, -0.0006792768836021423, -0.037407077848911285, -0.010335549712181091, 0.0017948135500773787, -0.08549519628286362, 2.406382373010274e-05, 0.017157597467303276, 0.0005072617204859853, 0.006330158095806837, 0.0347602404654026, 0.0006170586566440761, 0.011442302726209164, 0.04928271099925041, -0.035486362874507904, 0.01926569826900959, -0.02457108534872532, -0.0009698727517388761, 0.026421528309583664, 0.037430498749017715, 0.028084587305784225, -0.016044989228248596, -0.07636009156703949, 0.06118176877498627, -0.024219734594225883, -0.008028349839150906, 0.030871964991092682, 0.01446391362696886, 0.02136208675801754, 0.0038033651653677225, 0.0026219503488391638, 0.008660780265927315, 0.04684668406844139, 0.026843149214982986, -0.047221455723047256, -0.0012612005230039358, 0.0007590626482851803, 0.0018826511222869158, -0.01708732731640339, 0.0037565184757113457, 0.013995446264743805, -0.00199098396115005, 0.01706390455365181, 0.008859879337251186, -0.0344323106110096, 0.020518846809864044, -0.010306269861757755, 0.01250806450843811, -0.02407919429242611, -0.03738365322351456, 0.013456709682941437, 0.007624297868460417, 0.004242552910000086, -0.03347195312380791, -0.0023013432510197163, 0.04448092728853226, 0.01240265928208828, -0.015611656941473484, 0.013948599807918072, -0.00035519301309250295, 0.01882065460085869, -0.006892318371683359, 0.010973835363984108, -0.016454897820949554, 4.494811219046824e-05, -0.024102618917822838, -0.0008608077769167721, 0.012964819557964802, 0.027335040271282196, -0.002276455983519554, 0.0050272345542907715, -0.026444952934980392, 0.024688201025128365, -0.03408096358180046, -0.04989171773195267, 0.00870177149772644, 0.011670679785311222, -0.007712135091423988, -0.00555425975471735, -0.028037739917635918, -0.000609372858889401, -0.0628214031457901, -0.008777896873652935, -0.019195428118109703, 0.008221592754125595, 0.014862109906971455, 0.028623323887586594, 0.015037785284221172, 0.020319748669862747, -0.00598173588514328, -0.008326997980475426, 0.010370684787631035, 0.004248408600687981, -0.0520935133099556, -0.017017057165503502, 0.032722409814596176, -0.00011528675531735644, -0.0173801202327013, -0.031527817249298096, -0.018715249374508858, -0.006066645495593548, -0.0098787946626544, -0.015002650208771229, -0.03066115453839302, -0.004119580145925283, 0.005267323926091194, 0.006710787303745747, -0.002163731260225177, 0.005486917681992054, -0.012578334659337997, 0.01631435751914978, 0.0030274668242782354, 0.004599758889526129, 0.03412780910730362, 0.023118838667869568, 0.003958544693887234, -0.009808524511754513, 0.032980065792798996, 0.021116143092513084, -0.01035897247493267, -0.0285062063485384, -0.0017274714773520827, 0.008245016448199749, 0.015658503398299217, 0.03194943815469742, 0.028295395895838737, -0.025695405900478363, -0.027545848861336708, -0.0058119166642427444, -0.025461172685027122, 0.03614221513271332, 0.01776660420000553, 0.0183053407818079, 0.0009120463510043919, -0.012824279256165028, -0.01853957399725914, -0.015646792948246002, 0.07237812876701355, -0.0013849050737917423, -0.01446391362696886, 0.038929592818021774, 0.021537762135267258, -0.006488265469670296, -0.02970079705119133, 0.004154715221375227, 0.026585493236780167, -0.038414280861616135, 0.008116187527775764, -0.02320081926882267, 0.01843417063355446, -0.0011960543924942613, -0.02970079705119133, 0.010763025842607021, 0.007536460179835558, -0.020753080025315285, -0.017415255308151245, 0.025859368965029716, -0.002895710524171591, -0.0005054317880421877, -0.01892605982720852, -0.014381932094693184, 0.054435845464468, 0.012226983904838562, 0.0380629301071167, -0.023036856204271317, 0.01597471907734871, 0.008561231195926666, 0.03342510759830475, 0.03490077704191208, -0.019535066559910774, 0.015037785284221172, 0.01065762061625719, 0.01719273254275322, -0.014721570536494255, -0.00980266835540533, -0.04003049060702324, -0.0471746101975441, 0.010288702324032784, -0.017075616866350174, -0.005138495471328497, 0.008930148556828499, 0.020390018820762634, 0.01166482362896204, -0.01108509674668312, 0.00934591330587864, -0.023552170023322105, -0.0016249943291768432, -0.027850352227687836, 0.01973416469991207, 0.01740354299545288, 0.005317098461091518, 0.015916161239147186, -0.013960311189293861, -0.011992750689387321, 0.01228554267436266, 0.03565032407641411, 0.008924293331801891, -0.04424669221043587, -0.027053959667682648, -0.016138682141900063, 0.0045324163511395454, -0.00924636423587799, -0.035744018852710724, 0.009638705290853977, -0.009949063882231712, -0.024360274896025658, -0.028295395895838737, 0.02602333202958107, -0.011910769157111645, 0.010932845063507557, -0.017731469124555588, 0.03869536146521568, 0.00315922312438488, 0.02482874132692814, -0.010534647852182388, -0.01770804636180401, 0.03508816659450531, 0.011711671017110348, 0.002575103659182787, 0.04415299743413925, -0.002138843759894371, -0.01434679701924324, 0.043520569801330566, 0.011348608881235123, -0.027803506702184677, -0.017391830682754517, -0.01988641731441021, -0.025859368965029716, -0.004046382382512093, -0.0010943092638626695, 0.04129534959793091, 0.008116187527775764, 0.0024682346265763044, -0.03148097172379494, 0.010101315565407276, 0.0007854138966649771, -0.026889996603131294, -0.0022837757132947445, 0.022978298366069794, -0.0180242620408535, -0.02037830650806427, -0.023036856204271317, 0.044574618339538574, -0.05171873793005943, -0.018188225105404854, 0.026632338762283325, -0.00592317758128047, -0.00894771609455347, 0.0344323106110096, 0.03949175402522087, -0.01446391362696886, -0.005112144164741039, -0.0009749965975061059, 0.015681928023695946, 0.00198366423137486, 0.006810336373746395, -0.011454014107584953, -0.00280640902929008, 0.03396384418010712, 0.0056450255215168, 0.0034461591858416796, -0.06914570182561874, -0.01926569826900959, 0.024664778262376785, 0.0034900777973234653, -0.023610727861523628, 0.021291816607117653, 0.009831947274506092, 0.006406283937394619, 0.017075616866350174, -0.004772505722939968, 0.021912535652518272, 0.02501612901687622, -0.01654859073460102, 0.001125784358009696, 0.031317006796598434, -0.0018899708520621061, 0.020425153896212578, 0.016899941489100456, -0.009732398204505444, -0.03021611087024212, -0.0016586653655394912, 0.002012943383306265, -0.01856299862265587, -0.022381002083420753, -0.00334368203766644, 0.031270161271095276, 0.015506251715123653, -0.020987313240766525, -0.028623323887586594, -0.00499795563519001, 0.02273235283792019, 0.002876679180189967, 0.023751268163323402, -0.02405577152967453, -0.012332389131188393, -0.022978298366069794, -0.017309850081801414, -0.017953991889953613, -0.0012743761762976646, 0.015201748348772526, 0.02379811555147171, 0.0009976879227906466, -0.025461172685027122, 0.03876563161611557, 0.04635479301214218, -0.0005061637493781745, 0.04565209150314331, 0.013585537672042847, 0.009099967777729034, -0.014112562872469425, 0.04026472568511963, -0.01228554267436266, -0.011126087047159672, 0.009094112552702427, -0.01990984007716179, -0.007378352340310812, 0.0021315240301191807, 0.016267510131001472, -0.0022296092938631773, -0.007975648157298565, -0.022252174094319344, 0.033237721771001816, 0.0031533674336969852, 0.01066933199763298, -0.03159808740019798, 0.004690524190664291, -0.00870177149772644, 0.02628098987042904, 0.022263886407017708, 0.027100805193185806, 0.020905332639813423, -0.003334898268803954, 0.0013541618827730417, -0.0005903413984924555, -0.0013995446497574449, 0.024500815197825432, -0.011623833328485489, 0.037711579352617264, -0.039632294327020645, -0.021174700930714607, 0.006816192530095577, -0.016864806413650513, -0.005914393812417984, -0.006710787303745747, 0.023657575249671936, -0.010399963706731796, 0.01819993555545807, -0.012437794357538223, 0.0373368076980114, 0.02050713635981083, 0.019312545657157898, -0.028646746650338173, -0.009287354536354542, 0.0048954784870147705, -0.010938700288534164, 0.004898406099528074, 0.009053121320903301, -0.0017494307830929756, 0.046284522861242294, 0.0289512500166893, -0.008649068884551525, 0.026187295094132423, 0.013796348124742508, -0.018984617665410042, -0.0333079919219017, 0.011957615613937378, 0.034736815840005875, -0.027850352227687836, 0.005691871978342533, -0.0564502514898777, 0.005384440533816814, 0.0034432311076670885, -0.021045872941613197, -0.016536878421902657, 0.0002453961060382426, -0.023985501378774643, -0.041389044374227524, -0.04373138025403023, -0.012800856493413448, 0.041107963770627975, -0.021350376307964325, 0.010042757727205753, -0.005366872996091843, 0.018082819879055023, -0.016970211640000343, -0.009954920038580894, -0.022568389773368835, 0.018867501989006996, -0.040803462266922, -0.017438678070902824, 0.020987313240766525, 0.030052147805690765, -0.006950876675546169, -0.014264814555644989, -0.015892736613750458, 0.008883302100002766, -0.011863922700285912, -0.005302459001541138, -0.02871701680123806, -0.006611238233745098, 0.009984198957681656, 0.016771111637353897, -0.029115213081240654, -0.024008924141526222, -0.029864760115742683, 0.023118838667869568, 0.022135058417916298, 0.02454766258597374, -0.00926978699862957, -0.00592317758128047, 0.00946302991360426, 0.043356604874134064, 0.010575639083981514, -0.006599526386708021, 0.0035896271001547575, -0.010054469108581543, -0.010118883103132248, -0.011811220087110996, 0.04567551612854004, 0.012004462070763111, -0.008379700593650341, 0.010118883103132248, -0.009088256396353245, 0.04391876608133316, -0.02125668153166771, -0.012086444534361362, 0.009064832702279091, 0.015658503398299217, -0.012835991568863392, -0.01905488781630993, -0.016068411991000175, 0.015553099103271961, -0.020671099424362183, -0.01680624671280384, -0.025578288361430168, 0.028670169413089752, -0.006095924414694309, 0.034947626292705536, -0.002399428514763713, -0.06343040615320206, 0.018785519525408745, -0.0013578218640759587, 0.04710434004664421, 0.03946832939982414, -0.0037243112456053495, 0.01905488781630993, -0.0026658689603209496, 0.0029542690608650446, 0.004564623814076185, -0.0081454673781991, -0.012262118980288506, 0.008373844437301159, -0.008941860869526863, 0.032722409814596176, -0.016794536262750626, -0.019441373646259308, 0.006751778069883585, 0.00686303898692131, -0.00651168916374445, -0.007460334338247776, 0.04696379974484444, 0.008239160291850567, -0.03335483744740486, 0.018832366913557053, 0.004102012608200312, -0.025390902534127235, 0.01065762061625719, -0.01654859073460102, -0.02946656383574009, 0.030239533632993698, 0.019324256107211113, -0.04523047059774399, -0.029326023533940315, -0.002323302673175931, 0.04000706598162651, -0.010546359233558178, 0.01877380907535553, 0.010282847099006176, 0.008444114588201046, -0.025695405900478363, -0.020753080025315285, 0.004590975120663643, -0.024969281628727913, 0.006300878711044788, -0.02384496107697487, -0.02335307188332081, 0.002449203049764037, -0.015119766816496849, 0.034479159861803055, 0.01667741872370243, -0.011711671017110348, -0.016747688874602318, -0.009843659587204456, 0.0009713366744108498, 0.05382683873176575, -0.01599814184010029, 0.0009735326166264713, 0.008461682125926018, -0.019968397915363312, 0.009990055114030838, 0.010944556444883347, 0.02001524530351162, -0.015705350786447525, -0.008801320567727089, -0.00490718986839056, -0.03707914799451828, 0.007782405242323875, 0.005273179616779089, -0.008836455643177032, -0.0012487568892538548, 0.027194499969482422, -0.0003548270324245095, -0.014440489932894707, 0.01263689249753952, -0.020706234499812126, 0.006101780571043491, -0.014311661943793297, -0.0267728790640831, 0.014311661943793297, -0.005776781588792801, 0.0034080962650477886, 0.020905332639813423, 0.01263689249753952, -0.001147011760622263, 0.01510805543512106]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the length of the embedding vector is 1536 dimensions for `text-embedding-3-small`."
      ],
      "metadata": {
        "id": "wybQf7OkrFWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W11311Fvb6d",
        "outputId": "b1cc6bb1-ba82-4c60-d32a-e664d6746f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To solve the problem of the lack of a single all-purpose embedding model [Muennighoff et al](https://arxiv.org/abs/2210.07316) (2022) introduced the Massive Text Embedding Benchmark ([MTEB](https://huggingface.co/spaces/mteb/leaderboard)) leaderboard which is a good place to start when selecting a model. It spans eight embedding tasks covering multiple datasets and languages, which are constantly updated, and against which model performance is evaluated. It can be used to help select the most suitable model for fine-tuning for a specific domain and/or task.\n",
        "\n",
        "\n",
        "Muennighoff et al's comprehensive study concluded that the field has yet to converge on a universal text embedding method and scale it up sufficiently to provide state-of-the-art results on all embedding tasks. [Hongliu Cao](https://arxiv.org/abs/2406.01607) (2024) reviews recent advances in universal text embedding models with a focus on the top performing text embeddings on MTEB. Four different eras of text embedding are identified, from Count-based embeddings (with dimensionality reduction techniques), to Static dense word embeddings, Contextualised embeddings, and finally Universal text embeddings.\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://raw.githubusercontent.com/alisonmitchell/Biomedical-Knowledge-Graph/main/02_Exploratory_Data_Analysis/images/2406.01607_Recent_advances_in_text_embedding_H_Cao_2024.png\"\n",
        "         alt=\"The 4 different eras of text embeddings\"  width=\"100%\" height=\"auto\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Fig 1.</b>The 4 different eras of text embeddings. 1st era: Count-based Embeddings (with dimension reduction techniques);<br/> 2nd era: Static dense word embeddings, 3rd era: Contextualized embeddings; 4th era: Universal text embeddings.<br/> <a href=\"https://arxiv.org/pdf/2406.01607\">([2406.01607] Recent advances in text embedding, H Cao, 2024)</a>.<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The latter is defined as 'a unified comprehensive\n",
        "text embedding model that can address a multitude of input\n",
        "text length, downstream tasks, domains and languages'. The overall performance on MTEB English benchmarks is improved by such models especially on Retrieval, Reranking, Clustering and Pair Classification tasks, however, there is still no single universal model that achieves SOTA performance on all benchmarks, with further improvements to be made in summarisation tasks, language universality, and domain diversity.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lwVCmZrSyZdY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "\n",
        "* https://medium.com/@kirudang/language-model-history-before-and-after-transformer-the-ai-revolution-bedc7948a130\n",
        "\n",
        "* https://viso.ai/deep-learning/representation-learning/\n",
        "\n",
        "* https://towardsdatascience.com/text-embeddings-comprehensive-guide-afd97fce8fb5\n",
        "\n",
        "* https://medium.com/mantisnlp/text-embedding-models-how-to-choose-the-right-one-fd6bdb7ee1fd\n",
        "\n",
        "* https://towardsdatascience.com/explore-semantic-relations-in-corpora-with-embedding-models-0a6d64c3ec7f\n",
        "\n",
        "* https://github.com/centre-for-humanities-computing/embedding-explorer\n",
        "\n",
        "* https://centre-for-humanities-computing.github.io/embedding-explorer/\n",
        "\n",
        "* https://realpython.com/chromadb-vector-database/\n",
        "\n",
        "* https://www.pinecone.io/learn/series/nlp/sentence-embeddings/\n",
        "\n",
        "* https://www.pinecone.io/learn/series/nlp/dense-vector-embeddings-nlp/\n",
        "\n",
        "* https://platform.openai.com/docs/guides/embeddings\n",
        "\n",
        "* Vaswani, A et al. (2017). Attention Is All You Need. [arXiv:1706.03762](https://arxiv.org/pdf/1706.03762)\n",
        "\n",
        "* Devlin, J et al. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. [arXiv:1810.04805](https://arxiv.org/pdf/1810.04805)\n",
        "\n",
        "* Reimers, N. and Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. [arXiv:1908.10084](https://arxiv.org/pdf/1908.10084)\n",
        "\n",
        "* Naseem, U. et al. (2020). A Comprehensive Survey on Word Representation Models: From Classical to State-Of-The-Art Word Representation Language Models. [arXiv:2010.15036](https://arxiv.org/pdf/2010.15036)\n",
        "\n",
        "* Muennighoff, N. et al. (2022). MTEB: Massive Text Embedding Benchmark. [arXiv:2210.07316](https://arxiv.org/abs/2210.07316)\n",
        "\n",
        "* Su, H. et al. (2022). One Embedder, Any Task: Instruction-Finetuned Text Embeddings. [arXiv:2212.09741](https://arxiv.org/pdf/2212.09741)\n",
        "\n",
        "* Cao, H. (2024). Recent advances in text embedding: A Comprehensive Review of Top-Performing Methods on the MTEB Benchmark. [arXiv:2406.01607](https://arxiv.org/pdf/2406.01607)"
      ],
      "metadata": {
        "id": "QnMWw2GMZT2m"
      }
    }
  ]
}